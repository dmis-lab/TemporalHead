{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import random\n",
    "from random import shuffle\n",
    "from collections import defaultdict\n",
    "from rich import print as rprint\n",
    "from functools import partial\n",
    "\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformers import LlamaForCausalLM\n",
    "\n",
    "from eap.metrics import logit_diff, direct_logit\n",
    "from eap.graph import Graph\n",
    "from eap.dataset import EAPDataset\n",
    "from eap.attribute import attribute\n",
    "from eap.evaluate import evaluate_graph, evaluate_baseline,get_circuit_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "model_name = \"Llama-2-7b-chat-hf\"\n",
    "\n",
    "model = HookedTransformer.from_pretrained(MODEL_PATH, device=\"cuda:0\", fold_ln=False, center_writing_weights=False, center_unembed=False)\n",
    "model.cfg.use_split_qkv_input = True\n",
    "model.cfg.use_attn_result = True\n",
    "model.cfg.use_hook_mlp_in = True\n",
    "\n",
    "# If model has Grouped-Query Attention (GQA), make the params below false.\n",
    "# model.cfg.use_split_qkv_input = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Temporal Dataset ###\n",
    "\n",
    "# Set target year for clean run\n",
    "target_time = \"1999\"\n",
    "target_category = \"sports\"\n",
    "folder_path = './data/Temporal'\n",
    "\n",
    "matched_file = None\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.json') and f'time_{target_category}' in filename:\n",
    "        matched_file = os.path.join(folder_path, filename)\n",
    "        break\n",
    "\n",
    "# Load the matched JSON file\n",
    "if matched_file:\n",
    "    with open(matched_file, 'r') as f:\n",
    "        data_json = json.load(f)\n",
    "    print(f\"Loaded file: {matched_file}\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"No file matching category '{target_category}' found.\")\n",
    "\n",
    "# Extract prompt templates and samples\n",
    "prompt_template = data_json[\"prompt_templates\"][0]\n",
    "samples = data_json[\"samples\"]\n",
    "\n",
    "# Generate dataset rows\n",
    "dataset_rows = []\n",
    "\n",
    "# Filter samples for the target_time\n",
    "for sample in samples:\n",
    "    if sample[\"time\"] == target_time:\n",
    "        subject = sample[\"subject\"]\n",
    "        time_clean = sample[\"time\"]\n",
    "        object_clean = sample[\"object\"]\n",
    "\n",
    "        # Find corrupted samples (different time and different object for the same subject)\n",
    "        for corrupted_sample in samples:\n",
    "            if corrupted_sample[\"subject\"] == subject and corrupted_sample[\"time\"] != time_clean:\n",
    "                time_corrupted = corrupted_sample[\"time\"]\n",
    "                object_corrupted = corrupted_sample[\"object\"]\n",
    "\n",
    "                # Skip if objects are the same\n",
    "                if object_clean == object_corrupted:\n",
    "                    continue\n",
    "\n",
    "                # Tokenize object labels (assuming model.tokenizer is predefined)\n",
    "                clean_token_ids = model.tokenizer(object_clean, add_special_tokens=False).input_ids\n",
    "                corrupted_token_ids = model.tokenizer(object_corrupted, add_special_tokens=False).input_ids\n",
    "\n",
    "                # Append row with all required columns\n",
    "                dataset_rows.append({\n",
    "                    \"clean\": prompt_template.format(time=time_clean, subject=subject),\n",
    "                    \"corrupted\": prompt_template.format(time=time_corrupted, subject=subject),\n",
    "                    \"country_idx\": clean_token_ids[0],  # First token of object in clean run\n",
    "                    \"corrupted_country_idx\": corrupted_token_ids[0]  # First token of object in corrupted run\n",
    "                })\n",
    "                \n",
    "                # # If the model is Phi, use the code below\n",
    "                # dataset_rows.append({\n",
    "                #     \"clean\": prompt_template.format(time_clean, subject),\n",
    "                #     \"corrupted\": prompt_template.format(time_corrupted, subject),\n",
    "                #     \"country_idx\": clean_token_ids[1],\n",
    "                #     \"corrupted_country_idx\": corrupted_token_ids[1]\n",
    "                # })\n",
    "\n",
    "# Create DataFrame and save as CSV\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "df.to_csv(f'./data/{target_time}_temporal_knowledge_{target_category}.csv', index=False)\n",
    "\n",
    "print(f\"Filtered dataset created and saved to '{target_time}_temporal_knowledge_{target_category}.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# Temporal Dataset ###########################\n",
    "### For More Detailed Circuit, Use this version for Dataset Generation ###\n",
    "\n",
    "# Set target year and category\n",
    "target_time = \"1999\"\n",
    "target_category = \"sports\"\n",
    "\n",
    "matched_file = None\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.json') and f'time_{target_category}' in filename:\n",
    "        matched_file = os.path.join(folder_path, filename)\n",
    "        break\n",
    "\n",
    "if not matched_file:\n",
    "    raise FileNotFoundError(f\"No file matching category '{target_category}' found.\")\n",
    "\n",
    "with open(matched_file, 'r') as f:\n",
    "    data_json = json.load(f)\n",
    "print(f\"Loaded file: {matched_file}\")\n",
    "\n",
    "prompt_template = data_json[\"prompt_templates\"][0]\n",
    "samples = data_json[\"samples\"]\n",
    "\n",
    "subject_rows = defaultdict(list)\n",
    "\n",
    "for sample in samples:\n",
    "    if sample[\"time\"] != target_time:\n",
    "        continue\n",
    "    subject = sample[\"subject\"]\n",
    "    time_clean = sample[\"time\"]\n",
    "    object_clean = sample[\"object\"]\n",
    "\n",
    "    for corrupted in samples:\n",
    "        if corrupted[\"subject\"] != subject or corrupted[\"time\"] == time_clean:\n",
    "            continue\n",
    "        object_corr = corrupted[\"object\"]\n",
    "        if object_clean == object_corr:\n",
    "            continue\n",
    "\n",
    "        clean_ids = model.tokenizer(object_clean, add_special_tokens=False).input_ids\n",
    "        corr_ids  = model.tokenizer(object_corr,   add_special_tokens=False).input_ids\n",
    "\n",
    "        row = {\n",
    "            \"clean\": prompt_template.format(time=time_clean, subject=subject),\n",
    "            \"corrupted\": prompt_template.format(time=corrupted[\"time\"], subject=subject),\n",
    "            \"country_idx\": clean_ids[0],\n",
    "            \"corrupted_country_idx\": corr_ids[0]\n",
    "        }\n",
    "        subject_rows[subject].append(row)\n",
    "\n",
    "output_dir = './data'\n",
    "\n",
    "for subject, rows in subject_rows.items():\n",
    "    if not rows:\n",
    "        continue\n",
    "    df_subj = pd.DataFrame(rows)\n",
    "    safe_subj = subject.replace(\" \", \"_\").lower()\n",
    "    out_path = os.path.join(\n",
    "        output_dir,\n",
    "        f\"{target_time}_{target_category}_{safe_subj}.csv\"\n",
    "    )\n",
    "    df_subj.to_csv(out_path, index=False)\n",
    "    print(f\"Saved {len(rows)} rows for subject '{subject}' â†’ {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Time Invariant Dataset ###\n",
    "\n",
    "target_category = \"roman_numerals\"\n",
    "folder_path = './data/Invariant'\n",
    "\n",
    "matched_file = None\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.json') and f'{target_category}' in filename:\n",
    "        matched_file = os.path.join(folder_path, filename)\n",
    "        break\n",
    "\n",
    "# Load the matched JSON file\n",
    "if matched_file:\n",
    "    with open(matched_file, 'r') as f:\n",
    "        data_json = json.load(f)\n",
    "    print(f\"Loaded file: {matched_file}\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"No file matching category '{target_category}' found.\")\n",
    "\n",
    "# Extract the prompt template and samples\n",
    "prompt_template = data_json[\"prompt_templates\"][0]\n",
    "samples = data_json[\"samples\"]\n",
    "\n",
    "dataset_rows = []\n",
    "\n",
    "for sample in samples:\n",
    "    # Clean sample\n",
    "    subject_clean = sample[\"subject\"]\n",
    "    object_clean = sample[\"object\"]\n",
    "    clean_str = prompt_template.format(subject_clean)\n",
    "\n",
    "    # All corrupted candidates: samples with a different object\n",
    "    corrupted_candidates = [\n",
    "        s for s in samples if s[\"object\"] != object_clean\n",
    "    ]\n",
    "    if not corrupted_candidates:\n",
    "        continue\n",
    "\n",
    "    # Shuffle candidates for randomness\n",
    "    shuffle(corrupted_candidates)\n",
    "\n",
    "    # Iterate over all corrupted samples for the same subject\n",
    "    for corr_samp in corrupted_candidates:\n",
    "        subject_corr = corr_samp[\"subject\"]\n",
    "        object_corr = corr_samp[\"object\"]\n",
    "        corrupted_str = prompt_template.format(subject_corr)\n",
    "\n",
    "        # Tokenize the clean and corrupted strings\n",
    "        model.cfg.default_prepend_bos = False  # Prevent BOS token auto-insertion\n",
    "        clean_tokens = model.to_str_tokens(clean_str)\n",
    "        corrupted_tokens = model.to_str_tokens(corrupted_str)\n",
    "\n",
    "        # Check token length consistency\n",
    "        if len(clean_tokens) == len(corrupted_tokens):\n",
    "            # Token IDs for clean and corrupted objects\n",
    "            clean_obj_token_ids = model.tokenizer(object_clean, add_special_tokens=False).input_ids\n",
    "            corr_obj_token_ids = model.tokenizer(object_corr, add_special_tokens=False).input_ids\n",
    "            clean_obj_idx = clean_obj_token_ids[0] if clean_obj_token_ids else None\n",
    "            corr_obj_idx = corr_obj_token_ids[0] if corr_obj_token_ids else None\n",
    "            \n",
    "            # If the model is Phi, use the code below\n",
    "            # clean_obj_idx = clean_obj_token_ids[1] if clean_obj_token_ids else None\n",
    "            # corr_obj_idx = corr_obj_token_ids[1] if corr_obj_token_ids else None\n",
    "\n",
    "            # Add a row for each corrupted example\n",
    "            dataset_rows.append({\n",
    "                \"clean\": clean_str,\n",
    "                \"corrupted\": corrupted_str,\n",
    "                \"object_clean\": object_clean,\n",
    "                \"object_corrupted\": object_corr,\n",
    "                \"country_idx\": clean_obj_idx,\n",
    "                \"corrupted_country_idx\": corr_obj_idx\n",
    "            })\n",
    "\n",
    "print(f\"Total rows with same token length: {len(dataset_rows)}\")\n",
    "\n",
    "# Save the dataset to CSV\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "df.to_csv(f'./data/{target_category}.csv', index=False)\n",
    "print(f\"Filtered dataset saved to {target_category}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Temporal Dataset with Alias ###\n",
    "\n",
    "target_time = \"2009\"\n",
    "target_category = \"sports\"\n",
    "folder_path = './data/Temporal'\n",
    "\n",
    "matched_file = None\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.json') and f'time_{target_category}' in filename:\n",
    "        matched_file = os.path.join(folder_path, filename)\n",
    "        break\n",
    "\n",
    "# Load the matched JSON file\n",
    "if matched_file:\n",
    "    with open(matched_file, 'r') as f:\n",
    "        data_json = json.load(f)\n",
    "    print(f\"Loaded file: {matched_file}\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"No file matching category '{target_category}' found.\")\n",
    "\n",
    "prompt_template = data_json[\"prompt_templates\"][0]\n",
    "samples = data_json[\"samples\"]\n",
    "alias_time_list = data_json.get(\"alias_time_templates\", [])\n",
    "alias_dict = { item[\"year\"]: item[\"template\"] for item in alias_time_list }\n",
    "\n",
    "dataset_rows = []\n",
    "model.cfg.default_prepend_bos = False\n",
    "\n",
    "for sample in samples:\n",
    "    if sample[\"time\"] == target_time:\n",
    "        subject = sample[\"subject\"]\n",
    "        time_clean = sample[\"time\"]\n",
    "        object_clean = sample[\"object\"]\n",
    "\n",
    "        # Clean prompt\n",
    "        alias_prompt_template = alias_dict.get(time_clean, None)\n",
    "        if alias_prompt_template:\n",
    "            clean_str = alias_prompt_template.format(subject)\n",
    "        else:\n",
    "            clean_str = prompt_template.format(time_clean, subject)\n",
    "\n",
    "        # Corrupted samples\n",
    "        corrupted_candidates = [\n",
    "            s for s in samples\n",
    "            if s[\"subject\"] == subject and s[\"time\"] != time_clean and s[\"object\"] != object_clean\n",
    "        ]\n",
    "        shuffle(corrupted_candidates)\n",
    "\n",
    "        # corrupted candidates\n",
    "        for corrupted_sample in corrupted_candidates:\n",
    "            time_corrupted = corrupted_sample[\"time\"]\n",
    "            object_corrupted = corrupted_sample[\"object\"]\n",
    "\n",
    "            # alias template\n",
    "            alias_prompt_corrupted = alias_dict.get(time_corrupted, None)\n",
    "            if alias_prompt_corrupted:\n",
    "                corrupted_str = alias_prompt_corrupted.format(subject)\n",
    "            else:\n",
    "                corrupted_str = prompt_template.format(time_corrupted, subject)\n",
    "\n",
    "            # to_str_tokens tokenize with length check\n",
    "            clean_tokens = model.to_str_tokens(clean_str)\n",
    "            corrupted_tokens = model.to_str_tokens(corrupted_str)\n",
    "\n",
    "            # skip to pass attention mask shape mismatch\n",
    "            if len(clean_tokens) != len(corrupted_tokens):\n",
    "                continue\n",
    "\n",
    "            # country_idx / corrupted_country_idx\n",
    "            clean_obj_token_ids = model.tokenizer(object_clean, add_special_tokens=False).input_ids\n",
    "            corrupted_obj_token_ids = model.tokenizer(object_corrupted, add_special_tokens=False).input_ids\n",
    "\n",
    "            if not clean_obj_token_ids or not corrupted_obj_token_ids:\n",
    "                continue\n",
    "\n",
    "            clean_obj_idx = clean_obj_token_ids[0]\n",
    "            corr_obj_idx = corrupted_obj_token_ids[0]\n",
    "            \n",
    "            # If the model is Phi, use the code below\n",
    "            # clean_obj_idx = clean_obj_token_ids[1]\n",
    "            # corr_obj_idx = corrupted_obj_token_ids[1]\n",
    "\n",
    "            dataset_rows.append({\n",
    "                \"clean\": clean_str,\n",
    "                \"corrupted\": corrupted_str,\n",
    "                \"object_clean\": object_clean,\n",
    "                \"object_corrupted\": object_corrupted,\n",
    "                \"country_idx\": clean_obj_idx,\n",
    "                \"corrupted_country_idx\": corr_obj_idx\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "out_csv_path = f'./data/{target_time}_temporal_knowledge_{target_category}_alias.csv'\n",
    "df.to_csv(out_csv_path, index=False)\n",
    "print(f\"Total rows with same token length: {len(dataset_rows)}\")\n",
    "print(f\"Filtered dataset created and saved to '{out_csv_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load dataset into EAPDataset ###\n",
    "dataset = EAPDataset(filename=f'./data/{target_time}_temporal_knowledge_{target_category}.csv', task='fact-retrieval')\n",
    "\n",
    "# subject = \"Nicolas Anelka\"\n",
    "# dataset = EAPDataset(filename=f\"{target_time}_{target_category}_{subject}.csv\")\n",
    "\n",
    "# dataset = EAPDataset(filename=\"./data/{target_category}.csv\", task='fact-retrieval')\n",
    "\n",
    "# dataset = EAPDataset(filename=f'./data/{target_time}_temporal_knowledge_{target_category}_alias.csv', task='fact-retrieval')\n",
    "dataloader = dataset.to_dataloader(batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Graph.from_model(model)\n",
    "start_time = time.time()\n",
    "\n",
    "attribute(\n",
    "    model, \n",
    "    g, \n",
    "    dataloader,  # Updated to use dataloader\n",
    "    partial(logit_diff, loss=True, mean=True), \n",
    "    method='EAP-IG',  # For multiple samples\n",
    "    ig_steps=100\n",
    ")\n",
    "\n",
    "g.apply_topn(5000, absolute=True)\n",
    "g.prune_dead_nodes()\n",
    "g.to_json(f'./graphs/{model_name}/graph_{target_time}_{target_category}.json')\n",
    "# g.to_json('./graphs/{model_name}/{target_category}.json')\n",
    "\n",
    "gz = g.to_graphviz()\n",
    "gz.draw(f'./graphs/{model_name}/graph_{target_time}_{target_category}.png', prog='dot')\n",
    "# gz.draw(f'./graphs/{model_name}/{target_category}.png', prog='dot')\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution_Time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_component_logits(logits, model, answer_token, top_k=10):\n",
    "    logits = utils.remove_batch_dim(logits)\n",
    "    # print(heads_out[head_name].shape)\n",
    "    probs = logits.softmax(dim=-1)\n",
    "    token_probs = probs[-1]\n",
    "    answer_str_token = model.to_string(answer_token)\n",
    "    sorted_token_probs, sorted_token_values = token_probs.sort(descending=True)\n",
    "    # Janky way to get the index of the token in the sorted list - I couldn't find a better way?\n",
    "    correct_rank = torch.arange(len(sorted_token_values))[\n",
    "        (sorted_token_values == answer_token).cpu()\n",
    "    ].item()\n",
    "    # answer_ranks = []\n",
    "    # answer_ranks.append((answer_str_token, correct_rank))\n",
    "    # String formatting syntax - the first number gives the number of characters to pad to, the second number gives the number of decimal places.\n",
    "    # rprint gives rich text printing\n",
    "    rprint(\n",
    "        f\"Performance on answer token:\\n[b]Rank: {correct_rank: <8} Logit: {logits[-1, answer_token].item():5.2f} Prob: {token_probs[answer_token].item():6.2%} Token: |{answer_str_token}|[/b]\"\n",
    "    )\n",
    "    for i in range(top_k):\n",
    "        print(\n",
    "            f\"Top {i}th token. Logit: {logits[-1, sorted_token_values[i]].item():5.2f} Prob: {sorted_token_probs[i].item():6.2%} Token: |{model.to_string(sorted_token_values[i])}|\"\n",
    "        )\n",
    "    # rprint(f\"[b]Ranks of the answer tokens:[/b] {answer_ranks}\")\n",
    "    \n",
    "def CRS(\n",
    "    baseline_perf: float, \n",
    "    circuit_perf: float, \n",
    "    alpha=1.0, \n",
    "    sf_bothpos=1.0,   # both are positive\n",
    "    sf_bothneg=0.5,   # both are negative\n",
    "    sf_bneg_cpos=0.8, # baseline < 0, circuit > 0\n",
    "    sf_bpos_cneg=0.6, # baseline > 0, circuit < 0\n",
    "    eps=1e-9\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Computes a single score between 0 and 100:\n",
    "      - baseline_perf: performance of the original system (float)\n",
    "      - circuit_perf: performance of the circuit-modified system (float)\n",
    "      - alpha: sensitivity to error\n",
    "      - sf_*: weighting factors for different sign scenarios\n",
    "      - eps: small constant to avoid division by zero or near-zero\n",
    "\n",
    "    return: float in [0, 100], indicating how much better/worse the circuit is compared to the original\n",
    "    \"\"\"\n",
    "    B = baseline_perf\n",
    "    C = circuit_perf\n",
    "\n",
    "    # ---- Determine the sign scenario ----\n",
    "    if B > 0:\n",
    "        if C >= 0:\n",
    "            sign_factor = sf_bothpos\n",
    "        else:\n",
    "            sign_factor = sf_bpos_cneg\n",
    "    else:\n",
    "        # B <= 0\n",
    "        if C >= 0:\n",
    "            sign_factor = sf_bneg_cpos\n",
    "        else:\n",
    "            sign_factor = sf_bothneg\n",
    "\n",
    "    # ---- Ideal case: both positive and C >= B => full score ----\n",
    "    if B > 0 and C >= B:\n",
    "        return 100.0\n",
    "\n",
    "    # ---- Compute distance ----\n",
    "    absB = abs(B) if abs(B) > eps else eps  # replace near-zero |B| with eps\n",
    "\n",
    "    if B > 0:\n",
    "        # When B is positive: higher is better => dist = max(0, B - C)\n",
    "        dist_val = max(0.0, B - C)\n",
    "    else:\n",
    "        # When B <= 0: zero or positive is better => dist = max(0, |C|)\n",
    "        dist_val = max(0.0, abs(C))\n",
    "\n",
    "    # ---- Normalize distance ----\n",
    "    dist_ratio = dist_val / absB\n",
    "\n",
    "    # ---- Convert distance to similarity (0 ~ 1) using exponential decay ----\n",
    "    similarity = math.exp(- alpha * dist_ratio)\n",
    "\n",
    "    # ---- Final score (scaled by sign factor) ----\n",
    "    final_score = 100.0 * sign_factor * similarity\n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = evaluate_baseline(model, dataloader, partial(logit_diff, loss=False, mean=False)).mean().item()\n",
    "results = evaluate_graph(model, g, dataloader, partial(logit_diff, loss=False, mean=False)).mean().item()\n",
    "\n",
    "print(f\"Original performance was {baseline}; the circuit's performance is {results}\")\n",
    "\n",
    "# CRS\n",
    "final_metric = CRS(\n",
    "    baseline_perf=baseline, \n",
    "    circuit_perf=results, \n",
    "    alpha=1.0,          \n",
    "    sf_bothpos=1.0,     \n",
    "    sf_bothneg=0.5,     \n",
    "    sf_bneg_cpos=0.8,   # baseline<0, circuit>0\n",
    "    sf_bpos_cneg=0.6    # baseline>0, circuit<0\n",
    ")\n",
    "print(f\"Circuit Single Score (0~100) = {final_metric:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simplifying graph with threshold ###\n",
    "\n",
    "tau = 0.1  # example threshold\n",
    "\n",
    "g.apply_threshold(threshold=tau, absolute=False)\n",
    "\n",
    "important_node_ids = set()\n",
    "for edge_name, edge in g.edges.items():\n",
    "    if edge.in_graph:\n",
    "        important_node_ids.add(edge.parent.name)\n",
    "        important_node_ids.add(edge.child.name)\n",
    "\n",
    "for node_name, node in g.nodes.items():\n",
    "    if node_name not in important_node_ids:\n",
    "        node.in_graph = False\n",
    "        \n",
    "for node_name in list(g.nodes.keys()):\n",
    "    if not g.nodes[node_name].in_graph:\n",
    "        del g.nodes[node_name]\n",
    "\n",
    "for edge_name in list(g.edges.keys()):\n",
    "    if not g.edges[edge_name].in_graph:\n",
    "        del g.edges[edge_name]\n",
    "\n",
    "gz = g.to_graphviz()\n",
    "gz.draw(f'./graphs/{model_name}/simplified_graph_{target_time}_{target_category}.png', prog='dot')\n",
    "# gz = g.to_graphviz_enhanced(score_threshold=0.3, threshold_type=\"below\", highlight_nodes=[\"a15.h0\", \"a18.h3\"],)\n",
    "# gz.draw(f'./graphs/{model_name}/simplified_graph_{target_time}_{target_category}.png', prog='dot')\n",
    "\n",
    "remain_node_count = len(g.nodes)\n",
    "remain_edge_count = len(g.edges)\n",
    "\n",
    "print(\"Simplified circuit creation complete!\")\n",
    "print(f\"Simplfied Graph: {remain_node_count} nodes, {remain_edge_count} edges\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knowledgecircuit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
