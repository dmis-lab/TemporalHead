{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nodes_from_simplified_json(dir_path):\n",
    "    \"\"\"\n",
    "    Iterate through .json files in the directory and collect data in the format:\n",
    "    { \"category\": \"yearXXXX\" / \"time_invariant\",\n",
    "      \"filename\": \"...\",\n",
    "      \"nodes\": set([...]) }\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    year_pattern = re.compile(r\"(\\d{4})\")  # 4-digit year\n",
    "\n",
    "    for filename in os.listdir(dir_path):\n",
    "        if not filename.endswith(\".json\"):\n",
    "            continue\n",
    "        filepath = os.path.join(dir_path, filename)\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        node_dict = data.get(\"nodes\", {})\n",
    "        node_set = set(node_dict.keys())\n",
    "\n",
    "        # Determine the category\n",
    "        match_year = year_pattern.search(filename)\n",
    "        if match_year:\n",
    "            year_str = match_year.group(1)\n",
    "            category = f\"year{year_str}\"\n",
    "        else:\n",
    "            category = \"time_invariant\"  # Assign to time_invariant if no year found\n",
    "\n",
    "        results.append({\n",
    "            \"category\": category,\n",
    "            \"filename\": filename,\n",
    "            \"nodes\": node_set\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "def get_nodes_in_all_files(files_and_nodes):\n",
    "    \"\"\"\n",
    "    Find nodes that appear in all files (intersection)\n",
    "    \"\"\"\n",
    "    if not files_and_nodes:\n",
    "        return set()\n",
    "\n",
    "    common_nodes = set(files_and_nodes[0][1])\n",
    "    for _, node_set in files_and_nodes[1:]:\n",
    "        common_nodes &= node_set\n",
    "\n",
    "    return common_nodes\n",
    "\n",
    "def get_nodes_in_threshold(files_and_nodes, threshold_ratio=0.9):\n",
    "    \"\"\"\n",
    "    Count how often each node appears across files in a category,\n",
    "    and treat nodes with appearance ratio above threshold_ratio (default: 0.99) as major.\n",
    "    \"\"\"\n",
    "    node_counter = Counter()\n",
    "    n_files = len(files_and_nodes)\n",
    "    for _, node_set in files_and_nodes:\n",
    "        for nd in node_set:\n",
    "            node_counter[nd] += 1\n",
    "\n",
    "    threshold_count = int(threshold_ratio * n_files + 0.9999999)\n",
    "    major_nodes = set(nd for nd, cnt in node_counter.items() if cnt >= threshold_count)\n",
    "    return major_nodes\n",
    "\n",
    "def analyze_nodes_by_category(data_list, threshold_ratio=0.9):\n",
    "    \"\"\"\n",
    "    data_list: [{ \"category\":..., \"filename\":..., \"nodes\": set([...]) }, ... ]\n",
    "\n",
    "    Key logic:\n",
    "    - A.2: Collect nodes that appear at least once in both temporal and time_invariant categories (excluding A.1).\n",
    "    - B, C, D: Follow the original 99% threshold logic.\n",
    "    \"\"\"\n",
    "    # (1) Build mapping from category to list of (filename, node_set)\n",
    "    cat_to_file_nodes = defaultdict(list)\n",
    "    for item in data_list:\n",
    "        cat = item[\"category\"]\n",
    "        fn = item[\"filename\"]\n",
    "        ns = item[\"nodes\"]\n",
    "        cat_to_file_nodes[cat].append((fn, ns))\n",
    "\n",
    "    # (2) Get all category names\n",
    "    all_categories = sorted(cat_to_file_nodes.keys())\n",
    "\n",
    "    # (3) A.1: Nodes that appear in 100% of all files (across all categories)\n",
    "    all_files_and_nodes = [(item[\"filename\"], item[\"nodes\"]) for item in data_list]\n",
    "    common_in_all = get_nodes_in_all_files(all_files_and_nodes)\n",
    "\n",
    "    # (4) A.2: Nodes that appear at least once in both temporal and time_invariant categories, excluding A.1\n",
    "    #   4-1) Separate temporal and invariant categories\n",
    "    temporal_cats = [c for c in all_categories if c.startswith(\"year\")]\n",
    "    ti_cats = [c for c in all_categories if c == \"time_invariant\"]\n",
    "\n",
    "    #   4-2) temporal_all: Union of all nodes in temporal categories\n",
    "    temporal_all = set()\n",
    "    for cat in temporal_cats:\n",
    "        for _, node_set in cat_to_file_nodes[cat]:\n",
    "            temporal_all |= node_set\n",
    "\n",
    "    #   4-3) invariant_all: Union of all nodes in time_invariant categories\n",
    "    invariant_all = set()\n",
    "    for cat in ti_cats:\n",
    "        for _, node_set in cat_to_file_nodes[cat]:\n",
    "            invariant_all |= node_set\n",
    "\n",
    "    #   4-4) found_in_both: (Intersection) nodes in both, excluding common_in_all\n",
    "    found_in_both = (temporal_all & invariant_all) - common_in_all\n",
    "\n",
    "    # (5) Keep track of \"99%+ major nodes\" for B.1/B.2\n",
    "    temporal_major_union = set()\n",
    "    for cat in temporal_cats:\n",
    "        t_major = get_nodes_in_threshold(cat_to_file_nodes[cat], threshold_ratio=threshold_ratio)\n",
    "        temporal_major_union |= t_major\n",
    "\n",
    "    invariant_major_union = set()\n",
    "    for cat in ti_cats:\n",
    "        i_major = get_nodes_in_threshold(cat_to_file_nodes[cat], threshold_ratio=threshold_ratio)\n",
    "        invariant_major_union |= i_major\n",
    "\n",
    "    # (5) B.1 Temporal-Only, B.2 Invariant-Only\n",
    "    temporal_only = temporal_major_union - invariant_major_union - common_in_all - found_in_both\n",
    "    invariant_only = invariant_major_union - temporal_major_union - common_in_all - found_in_both\n",
    "\n",
    "    # (6) C. Category-Specific Major Nodes (excluding A and B)\n",
    "    category_major_nodes = {}\n",
    "    for cat, fnodes_list in cat_to_file_nodes.items():\n",
    "        major_set = get_nodes_in_threshold(fnodes_list, threshold_ratio=threshold_ratio)\n",
    "        category_major_nodes[cat] = major_set - common_in_all - found_in_both - temporal_only - invariant_only\n",
    "\n",
    "    # (7) D. Missing Info\n",
    "    missing_info = defaultdict(list)\n",
    "    for cat, fnodes_list in cat_to_file_nodes.items():\n",
    "        # 1) Get major set for this category (threshold=0.99)\n",
    "        major_set = get_nodes_in_threshold(fnodes_list, threshold_ratio=threshold_ratio)\n",
    "\n",
    "        # 2) Exclude A.1 and A.2 (common_in_all and found_in_both)\n",
    "        c_candidates = major_set - common_in_all - found_in_both - temporal_only - invariant_only\n",
    "        \n",
    "        # 3) Define relevant_set as B âˆª C\n",
    "        if cat.startswith(\"year\"):\n",
    "            relevant_set = (temporal_only | c_candidates)\n",
    "        elif cat == \"time_invariant\":\n",
    "            relevant_set = (invariant_only | c_candidates)\n",
    "\n",
    "        # 4) For each file, check which relevant nodes are missing\n",
    "        for fn, node_set in fnodes_list:\n",
    "            missed = relevant_set - node_set\n",
    "            if missed:\n",
    "                missing_info[cat].append((fn, missed))\n",
    "\n",
    "    # Combine results into Markdown format\n",
    "    lines = []\n",
    "    lines.append(\"# Analysis of Simplified Graphs\\n\")\n",
    "\n",
    "    # A.1\n",
    "    lines.append(\"## A.1 Common in All Simplified Graphs (100% in each category)\\n\")\n",
    "    lines.append(f\"- **Common Nodes**: {sorted(common_in_all)}\\n\")\n",
    "\n",
    "    # A.2\n",
    "    lines.append(\"## A.2 Found in Both Temporal and Time-Invariant Categories\\n\")\n",
    "    lines.append(\"(Nodes that appear at least once in temporal AND at least once in time_invariant, excluding A.1)\\n\")\n",
    "    lines.append(f\"- **Found in Both**: {sorted(found_in_both)}\\n\")\n",
    "\n",
    "    # B\n",
    "    lines.append(\"## B. Temporal vs Time-Invariant\\n\")\n",
    "    lines.append(\"### B.1 Temporal-Only Nodes\\n\")\n",
    "    lines.append(f\"- {sorted(temporal_only)}\\n\")\n",
    "    lines.append(\"### B.2 Invariant-Only Nodes\\n\")\n",
    "    lines.append(f\"- {sorted(invariant_only)}\\n\")\n",
    "\n",
    "    # C\n",
    "    lines.append(\"\\n## C. Category-Specific Major Nodes (Excluding A & B)\\n\")\n",
    "    lines.append(\"| Category | Exclusive Major Nodes |\\n|---|---|\")\n",
    "    for cat in all_categories:\n",
    "        excl = category_major_nodes[cat]\n",
    "        if not excl:\n",
    "            lines.append(f\"| {cat} |  |\")\n",
    "        else:\n",
    "            lines.append(f\"| {cat} | {', '.join(sorted(excl))} |\")\n",
    "\n",
    "    # D\n",
    "    lines.append(\"\\n## D. Missing Info in Some Files\\n\")\n",
    "    lines.append(\"*(Nodes that are in A.2, B, or C but absent in certain files)*\\n\")\n",
    "    lines.append(\"| Category | Filename | Missing Nodes |\\n|---|---|---|\")\n",
    "    for cat in all_categories:\n",
    "        if cat not in missing_info:\n",
    "            continue\n",
    "        for (fn, missed) in missing_info[cat]:\n",
    "            lines.append(f\"| {cat} | {fn} | {', '.join(sorted(missed))} |\")\n",
    "\n",
    "    return \"\\n\".join(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Analysis of Simplified Graphs\n",
      "\n",
      "## A.1 Common in All Simplified Graphs (100% in each category)\n",
      "\n",
      "- **Common Nodes**: []\n",
      "\n",
      "## A.2 Found in Both Temporal and Time-Invariant Categories\n",
      "\n",
      "(Nodes that appear at least once in temporal AND at least once in time_invariant, excluding A.1)\n",
      "\n",
      "- **Found in Both**: ['a0.h22', 'a0.h25', 'a1.h15', 'a1.h24', 'a1.h27', 'a1.h28', 'a2.h13', 'a2.h16', 'a2.h17', 'a2.h2', 'a2.h24', 'a20.h14', 'a24.h14', 'a24.h24', 'a26.h14', 'a28.h7', 'a29.h10', 'a29.h5', 'a29.h9', 'a30.h12', 'a31.h27', 'a4.h17', 'a4.h30', 'a6.h1', 'input', 'logits', 'm0', 'm1', 'm10', 'm11', 'm12', 'm13', 'm14', 'm15', 'm16', 'm17', 'm18', 'm19', 'm2', 'm20', 'm21', 'm22', 'm23', 'm24', 'm25', 'm26', 'm27', 'm28', 'm29', 'm3', 'm30', 'm31', 'm4', 'm5', 'm6', 'm7', 'm8', 'm9']\n",
      "\n",
      "## B. Temporal vs Time-Invariant\n",
      "\n",
      "### B.1 Temporal-Only Nodes\n",
      "\n",
      "- ['a15.h0', 'a18.h3']\n",
      "\n",
      "### B.2 Invariant-Only Nodes\n",
      "\n",
      "- ['a19.h6']\n",
      "\n",
      "\n",
      "## C. Category-Specific Major Nodes (Excluding A & B)\n",
      "\n",
      "| Category | Exclusive Major Nodes |\n",
      "|---|---|\n",
      "| time_invariant |  |\n",
      "| year1999 |  |\n",
      "| year2004 |  |\n",
      "| year2009 |  |\n",
      "\n",
      "## D. Missing Info in Some Files\n",
      "\n",
      "*(Nodes that are in A.2, B, or C but absent in certain files)*\n",
      "\n",
      "| Category | Filename | Missing Nodes |\n",
      "|---|---|---|\n",
      "| time_invariant | simplified_geometric_shape.json | a19.h6 |\n",
      "| year1999 | simplified_graph_1999_v8.json | a15.h0, a18.h3 |\n",
      "| year1999 | simplified_graph_1999_v4_alias.json | a15.h0, a18.h3 |\n",
      "| year1999 | simplified_graph_1999_v1_alias.json | a15.h0, a18.h3 |\n",
      "| year1999 | simplified_graph_1999_v3_alias.json | a15.h0, a18.h3 |\n",
      "| year1999 | simplified_graph_1999_v2_condi.json | a18.h3 |\n",
      "| year1999 | simplified_graph_1999_v1_condi.json | a15.h0, a18.h3 |\n",
      "| year1999 | simplified_graph_1999_v2_alias.json | a15.h0 |\n",
      "| year2004 | simplified_graph_2004_v9.json | a15.h0, a18.h3 |\n",
      "| year2004 | simplified_graph_2004_v4_alias.json | a15.h0, a18.h3 |\n",
      "| year2004 | simplified_graph_2004_v3_alias.json | a15.h0, a18.h3 |\n",
      "| year2004 | simplified_graph_2004_v1_alias.json | a15.h0, a18.h3 |\n",
      "| year2004 | simplified_graph_2004_v10.json | a18.h3 |\n",
      "| year2004 | simplified_graph_2004_v1.2.json | a15.h0, a18.h3 |\n",
      "| year2004 | simplified_graph_2004_v2_new.json | a18.h3 |\n",
      "| year2009 | simplified_graph_2009_v3_alias.json | a15.h0, a18.h3 |\n",
      "| year2009 | simplified_graph_2009_v4_alias.json | a15.h0, a18.h3 |\n",
      "| year2009 | simplified_graph_2009_v2_alias.json | a15.h0 |\n",
      "| year2009 | simplified_graph_2009_v1_alias.json | a15.h0, a18.h3 |\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Llama-2-7b-chat-hf\"\n",
    "directory_path = f\"./graphs/{model_name}\"\n",
    "data_list = load_nodes_from_simplified_json(directory_path)\n",
    "md_report = analyze_nodes_by_category(data_list, threshold_ratio=0.9)\n",
    "print(md_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knowledgecircuit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
